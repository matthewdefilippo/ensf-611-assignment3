{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Matthew De Filippo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "(X, y) = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# Import the Decision Tree, Random Forest, and Gradient Boosting Machines regression models from sklearn.\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate the Decision Tree Regressor model with max_depth=5; random_state=0.\n",
    "model_decision_tree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "\n",
    "# Instantiate the Random Forest Classifier model with max_depth=5; random_state=0; max_features='sqrt' (default); \n",
    "# n_estimators=100 (default). \n",
    "model_random_forest = RandomForestRegressor(max_depth=5, random_state=0, max_features='sqrt', n_estimators=100)\n",
    "\n",
    "# Instantiate the Gradient Boosting Classifier model with max_depth=5; random_state=0; n_estimators=100 (default). \n",
    "model_gradient_boosting = GradientBoostingRegressor(max_depth=5, random_state=0, n_estimators=100)\n",
    "\n",
    "# Implement each machine learning model with X and y.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model_decision_tree.fit(X_train, y_train)\n",
    "model_random_forest.fit(X_train, y_train)\n",
    "model_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the average training and validation accuracy using mean squared error with cross-validation.\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores_decision_tree = cross_validate(model_decision_tree, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "scores_random_forest = cross_validate(model_random_forest, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "scores_gradient_boosting = cross_validate(model_gradient_boosting, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267c2894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>47.822974</td>\n",
       "      <td>74.045335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>49.158648</td>\n",
       "      <td>67.723347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GB</td>\n",
       "      <td>3.694308</td>\n",
       "      <td>23.546500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ML Model  Training Accuracy  Validation Accuracy\n",
       "0       DT          47.822974            74.045335\n",
       "1       RF          49.158648            67.723347\n",
       "2       GB           3.694308            23.546500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pandas DataFrame results with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB.\n",
    "# Add the results to the dataframe.\n",
    "results = pd.DataFrame({'ML Model': ['DT', 'RF', 'GB'], \n",
    "                        'Training Accuracy': [-scores_decision_tree['train_score'].mean(), -scores_random_forest['train_score'].mean(), -scores_gradient_boosting['train_score'].mean()], \n",
    "                        'Validation Accuracy': [-scores_decision_tree['test_score'].mean(), -scores_random_forest['test_score'].mean(), -scores_gradient_boosting['test_score'].mean()]})\n",
    "# Print the results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.830437</td>\n",
       "      <td>0.735184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.825750</td>\n",
       "      <td>0.758736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.986903</td>\n",
       "      <td>0.916155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ML Model  Training Accuracy  Validation Accuracy\n",
       "0       DT           0.830437             0.735184\n",
       "1       RF           0.825750             0.758736\n",
       "2       GB           0.986903             0.916155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Calculate the average training and validation accuracy using R2 score with cross-validation.\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores_decision_tree = cross_validate(model_decision_tree, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "scores_random_forest = cross_validate(model_random_forest, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "scores_gradient_boosting = cross_validate(model_gradient_boosting, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "# Create a pandas DataFrame results with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB.\n",
    "# Add the results to the dataframe.\n",
    "results = pd.DataFrame({'ML Model': ['DT', 'RF', 'GB'], \n",
    "                        'Training Accuracy': [scores_decision_tree['train_score'].mean(), scores_random_forest['train_score'].mean(), scores_gradient_boosting['train_score'].mean()], \n",
    "                        'Validation Accuracy': [scores_decision_tree['test_score'].mean(), scores_random_forest['test_score'].mean(), scores_gradient_boosting['test_score'].mean()]})\n",
    "# Print the results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "#### Question 1 Response:\n",
    "In assignment 2, we used a linear regression model and achieved training and validation r^2 scores of 0.61 and 0.64 respectively. As shown above, the results we have achieved with each of the decision tree, random forest, and gradient boosting models are superior. The best result was achieved with the gradient boosting model for which we achieved training and validation r^2 scores of 0.99 and 0.92 respectively.\n",
    "\n",
    "#### Question 2 Response:\n",
    "Out of the models tested, I would select the gradient boosting regressor because it achieved the best training and validation r^2 scores of 0.99 and 0.92 respectively. \n",
    "\n",
    "#### Question 3 Response:\n",
    "For the tree-based models, in order to improve accuracy we could look at increasing the amount of n_estimators or modifying the number of max_features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "The code was created by referencing the provided examples contained in Lab 4 - Decision Trees and SVC. I referenced and adapted the approach provided in the example to suit the assignment requirements.\n",
    "\n",
    "#### Question 2\n",
    "I completed the steps in the suggested order: 1 -> 2 -> 3 -> 4 -> 5.\n",
    "\n",
    "#### Question 3\n",
    "I did not use generative AI to complete this assignment.\n",
    "\n",
    "#### Question 4\n",
    "Yes. One issue I ran into was that I had originally used 'Classifier' decision tree and random forest models instead of 'Regressor. As a result, I was getting poor MSE and R^2 values. I asked a friend to review my code and he helped me to notice the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X is: 2314\n",
      "The shape of X is: (178, 13)\n",
      "The type of X is:\n",
      "Alcohol                         float64\n",
      "Malicacid                       float64\n",
      "Ash                             float64\n",
      "Alcalinity_of_ash               float64\n",
      "Magnesium                         int64\n",
      "Total_phenols                   float64\n",
      "Flavanoids                      float64\n",
      "Nonflavanoid_phenols            float64\n",
      "Proanthocyanins                 float64\n",
      "Color_intensity                 float64\n",
      "Hue                             float64\n",
      "0D280_0D315_of_diluted_wines    float64\n",
      "Proline                           int64\n",
      "dtype: object\n",
      "\n",
      "The size of y is: 178\n",
      "The shape of y is: (178,)\n",
      "The type of y is:\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "wine_df = pd.read_csv('wine.data', names = ['class', 'Alcohol', 'Malicacid', 'Ash', 'Alcalinity_of_ash', 'Magnesium', 'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols', 'Proanthocyanins', 'Color_intensity', 'Hue', '0D280_0D315_of_diluted_wines', 'Proline'] )\n",
    "X = wine_df.drop(['class'], axis=1)\n",
    "y = wine_df['class']\n",
    "\n",
    "print(f'The size of X is: {X.size}')\n",
    "print(f'The shape of X is: {X.shape}')\n",
    "print(f'The type of X is:\\n{X.dtypes}\\n')\n",
    "\n",
    "print(f'The size of y is: {y.size}')\n",
    "print(f'The shape of y is: {y.shape}')\n",
    "print(f'The type of y is:\\n{y.dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0      1    14.23       1.71  2.43               15.6        127   \n",
       "1      1    13.20       1.78  2.14               11.2        100   \n",
       "2      1    13.16       2.36  2.67               18.6        101   \n",
       "3      1    14.37       1.95  2.50               16.8        113   \n",
       "4      1    13.24       2.59  2.87               21.0        118   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color_intensity   Hue  0D280_0D315_of_diluted_wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "wine_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running X.isnull().sum() gives:\n",
      "\n",
      "Alcohol                         0\n",
      "Malicacid                       0\n",
      "Ash                             0\n",
      "Alcalinity_of_ash               0\n",
      "Magnesium                       0\n",
      "Total_phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid_phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color_intensity                 0\n",
      "Hue                             0\n",
      "0D280_0D315_of_diluted_wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n",
      "Running y.isnull().sum() gives: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print('Running X.isnull().sum() gives:\\n')\n",
    "print(X.isnull().sum())\n",
    "print(f'Running y.isnull().sum() gives: {y.isnull().sum()}')\n",
    "\n",
    "# Based on these results, we see that there are no missing values in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.698882</td>\n",
       "      <td>0.662808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.994721</td>\n",
       "      <td>0.929310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ML Model  Training Accuracy  Validation Accuracy\n",
       "0      SVC           0.698882             0.662808\n",
       "1       DT           0.994721             0.929310"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# Import SVC and DecisionTreeClassifier.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate models as SVC() and DecisionTreeClassifier(max_depth = 3).\n",
    "model_svc = SVC()\n",
    "model_decision_tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "# Implement the machine learning model with X and y.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model_svc.fit(X_train, y_train)\n",
    "model_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the average training and validation accuracy using cross_validate for the two different models.\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores_svc = cross_validate(model_svc, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "scores_decision_tree = cross_validate(model_decision_tree, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "# Create a pandas DataFrame results with columns: Training accuracy and Validation accuracy.\n",
    "results = pd.DataFrame({'ML Model': ['SVC', 'DT'], \n",
    "                        'Training Accuracy': [scores_svc['train_score'].mean(), scores_decision_tree['train_score'].mean()], \n",
    "                        'Validation Accuracy': [scores_svc['test_score'].mean(), scores_decision_tree['test_score'].mean()]})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model\n",
    "# The decision tree model gave the best results. \n",
    "# Therefore, we will use that to print the confusion matrix and classification report.\n",
    "\n",
    "predictions = model_decision_tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(170.97222222222223, 0.5, 'True Value')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_val, predictions)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('True Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.94      0.97        16\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, predictions, target_names=[\"1\", \"2\", \"3\"], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "#### Question 1\n",
    "With the SVC model, we achieve training and validation accuracies of 0.70 and 0.66 respectively. The best results are achieved with the decision tree classifier model; with this model, we achieve training and validation accuracies of 0.99 and 0.93 respectively.\n",
    "\n",
    "#### Question 2\n",
    "Two potential reasons that the support vector machines model did not work as well are:\n",
    " - We have not applied careful tuning of the required parameters such as C and gamma. We have simply applied the default values by using SVC().\n",
    " - No pre-processing has been performed.\n",
    "\n",
    "#### Question 3\n",
    "One sample was incorrectly classified in step 5.2. A single class 2 value was incorrectly classified as a class 1 value. All other values were correctly classified.\n",
    "\n",
    "#### Question 4\n",
    "Recall calculates the number of actual positives that we captured (true positives divided by total number of positives). Recall is important when the cost of false negatives is high.\n",
    "\n",
    "Precision calculates the number of samples that were predicted positive and are actually positive (true positives divided by total number of positive predictions). Precision is important when the cost of false positives is high.\n",
    "\n",
    "In this case, it can be argued that the cost of a false positive is higher as this would mislead the user to potentially purchase a bottle of wine that was not sourced from a particular cultivar. We can therefore prioritize precision in this scenario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "#### Question 1\n",
    "The code was created by referencing the provided examples contained in the lecture notes particularly \"SVM\" and \"Decision Trees Example\". I referenced and adapted the approach provided in the example to suit the assignment requirements.\n",
    "\n",
    "#### Question 2\n",
    "I completed the steps in the suggested order: 1 -> 2 -> 3 -> 4 -> 5.\n",
    "\n",
    "#### Question 3\n",
    "I did not use generative AI to complete this assignment.\n",
    "\n",
    "#### Question 4\n",
    "No; I did not run into any issues on this part of the assignment. Referencing the referenced examples and reviewing final findings with classmates helped me to be successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "#### Part 1 - Regression\n",
    "\n",
    "As shown above, the results we have achieved with each of the decision tree, random forest, and gradient boosting models are superior to those achieved on Assignment 2 using linear regression. The best result was achieved with the gradient boosting model for which we achieved training and validation r^2 scores of 0.99 and 0.92 respectively.\n",
    "\n",
    "This demonstrates the importance of finding a model that can adequately fit the data you are working with.\n",
    "\n",
    "#### Part 2 - Classification\n",
    "\n",
    "In this exercise, we classified wine based on 13 different attributes. Two models were used: an SVC() and a DecisionTreeClassifier(). The decision tree resulted in superior performance based on the calculated training and validation accuracy scores. This confirms the importance of pre-processing and tweaking parameters when working with SVC models; we did not perform these steps in this exercise and therefore did not achieve great results. The decision tree on the other hand was able to achieve fairly good results without any tweaking of parameters required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked the opportunity to apply more types of models and try them out on real datasets. It was interesting to see the results and relate them to the concepts learned in the lecture. This helped to reinforce the lecture material and gave a more clear understanding of the discussed concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.852243</td>\n",
       "      <td>0.810591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ML Model  Training Accuracy  Validation Accuracy\n",
       "0  LinearSVC           0.852243             0.810591"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# Import LinearSVC.\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Instantiate models as SVC() and DecisionTreeClassifier(max_iter = 5000).\n",
    "model_lsvc = LinearSVC()\n",
    "\n",
    "# Implement the machine learning model with X and y.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model_lsvc.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the average training and validation accuracy using cross_validate for the two different models.\n",
    "scores_lsvc = cross_validate(model_lsvc, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "# Create a pandas DataFrame results with columns: Training accuracy and Validation accuracy.\n",
    "results = pd.DataFrame({'ML Model': ['LinearSVC'], \n",
    "                        'Training Accuracy': [scores_lsvc['train_score'].mean()], \n",
    "                        'Validation Accuracy': [scores_lsvc['test_score'].mean()]})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b73dc44",
   "metadata": {},
   "source": [
    "Yes. Using LinearSVC improved the results when compared to the standard SVC model. Training accuracy improved from 0.70 to 0.85; validation accuracy improved from 0.66 to 0.81.\n",
    "\n",
    "While it is better than SVC, I would still not say that LinearSVC is a good fit for this dataset as superior results are achieved by using the DecisionTreeClassifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45dceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
